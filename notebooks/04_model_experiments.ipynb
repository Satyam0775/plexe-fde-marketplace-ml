{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e7b3243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1252Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9432afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53091cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ready: (80372, 4) (20196, 4)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/raw/\"\n",
    "\n",
    "orders = pd.read_csv(DATA_PATH + \"olist_orders_dataset.csv\")\n",
    "reviews = pd.read_csv(DATA_PATH + \"olist_order_reviews_dataset.csv\")\n",
    "order_items = pd.read_csv(DATA_PATH + \"olist_order_items_dataset.csv\")\n",
    "\n",
    "df = orders.merge(reviews, on=\"order_id\", how=\"inner\")\n",
    "df[\"low_rating\"] = (df[\"review_score\"] <= 2).astype(int)\n",
    "\n",
    "# Delivery delay\n",
    "orders[\"order_purchase_timestamp\"] = pd.to_datetime(orders[\"order_purchase_timestamp\"])\n",
    "orders[\"order_delivered_customer_date\"] = pd.to_datetime(orders[\"order_delivered_customer_date\"])\n",
    "orders[\"order_estimated_delivery_date\"] = pd.to_datetime(orders[\"order_estimated_delivery_date\"])\n",
    "\n",
    "orders[\"delivery_delay_days\"] = (\n",
    "    orders[\"order_delivered_customer_date\"] -\n",
    "    orders[\"order_estimated_delivery_date\"]\n",
    ").dt.days\n",
    "\n",
    "df = df.merge(\n",
    "    orders[[\"order_id\", \"delivery_delay_days\"]],\n",
    "    on=\"order_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df[\"delivery_delay_days\"] = df[\"delivery_delay_days\"].clip(-60, 30)\n",
    "\n",
    "# Monetary\n",
    "price_df = (\n",
    "    order_items.groupby(\"order_id\")[[\"price\", \"freight_value\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df = df.merge(price_df, on=\"order_id\", how=\"left\")\n",
    "\n",
    "# Chronological split\n",
    "df[\"order_purchase_timestamp\"] = pd.to_datetime(df[\"order_purchase_timestamp\"])\n",
    "df = df.sort_values(\"order_purchase_timestamp\")\n",
    "\n",
    "split_index = int(len(df) * 0.8)\n",
    "\n",
    "train_df = df.iloc[:split_index].copy()\n",
    "test_df = df.iloc[split_index:].copy()\n",
    "\n",
    "# Seller risk\n",
    "order_seller = order_items[[\"order_id\", \"seller_id\"]].drop_duplicates()\n",
    "train_df = train_df.merge(order_seller, on=\"order_id\", how=\"left\")\n",
    "test_df = test_df.merge(order_seller, on=\"order_id\", how=\"left\")\n",
    "\n",
    "seller_risk = (\n",
    "    train_df.groupby(\"seller_id\")[\"low_rating\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "seller_risk.columns = [\"seller_id\", \"seller_historical_risk\"]\n",
    "\n",
    "train_df = train_df.merge(seller_risk, on=\"seller_id\", how=\"left\")\n",
    "test_df = test_df.merge(seller_risk, on=\"seller_id\", how=\"left\")\n",
    "\n",
    "global_mean = train_df[\"low_rating\"].mean()\n",
    "\n",
    "train_df[\"seller_historical_risk\"] = train_df[\"seller_historical_risk\"].fillna(global_mean)\n",
    "test_df[\"seller_historical_risk\"] = test_df[\"seller_historical_risk\"].fillna(global_mean)\n",
    "\n",
    "# Final features\n",
    "feature_cols = [\n",
    "    \"delivery_delay_days\",\n",
    "    \"price\",\n",
    "    \"freight_value\",\n",
    "    \"seller_historical_risk\"\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[\"low_rating\"]\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[\"low_rating\"]\n",
    "\n",
    "print(\"Data ready:\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d4a050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delivery_delay_days       2490\n",
      "price                      656\n",
      "freight_value              656\n",
      "seller_historical_risk       0\n",
      "dtype: int64\n",
      "delivery_delay_days       378\n",
      "price                     103\n",
      "freight_value             103\n",
      "seller_historical_risk      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.isna().sum())\n",
    "print(X_test.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4760a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train missing total: 0\n",
      "Test missing total: 0\n",
      "Shapes: (80372, 4) (20196, 4)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Final Feature Matrix (SAFE COPY)\n",
    "# -----------------------------------\n",
    "\n",
    "feature_cols = [\n",
    "    \"delivery_delay_days\",\n",
    "    \"price\",\n",
    "    \"freight_value\",\n",
    "    \"seller_historical_risk\"\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols].copy()\n",
    "X_test = test_df[feature_cols].copy()\n",
    "\n",
    "y_train = train_df[\"low_rating\"]\n",
    "y_test = test_df[\"low_rating\"]\n",
    "\n",
    "# -----------------------------------\n",
    "# Impute Missing Values (TRAIN stats only)\n",
    "# -----------------------------------\n",
    "\n",
    "# Delivery delay\n",
    "delay_median = X_train[\"delivery_delay_days\"].median()\n",
    "X_train[\"delivery_delay_days\"] = X_train[\"delivery_delay_days\"].fillna(delay_median)\n",
    "X_test[\"delivery_delay_days\"] = X_test[\"delivery_delay_days\"].fillna(delay_median)\n",
    "\n",
    "# Price\n",
    "price_median = X_train[\"price\"].median()\n",
    "X_train[\"price\"] = X_train[\"price\"].fillna(price_median)\n",
    "X_test[\"price\"] = X_test[\"price\"].fillna(price_median)\n",
    "\n",
    "# Freight\n",
    "freight_median = X_train[\"freight_value\"].median()\n",
    "X_train[\"freight_value\"] = X_train[\"freight_value\"].fillna(freight_median)\n",
    "X_test[\"freight_value\"] = X_test[\"freight_value\"].fillna(freight_median)\n",
    "\n",
    "# -----------------------------------\n",
    "# Final Check\n",
    "# -----------------------------------\n",
    "\n",
    "print(\"Train missing total:\", X_train.isna().sum().sum())\n",
    "print(\"Test missing total:\", X_test.isna().sum().sum())\n",
    "print(\"Shapes:\", X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbff04c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "ROC-AUC: 0.5846200913161361\n",
      "Recall: 0.06577239290350498\n",
      "Precision: 0.3392857142857143\n",
      "F1: 0.11018484958318231\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "log_pred = log_model.predict(X_test)\n",
    "log_prob = log_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, log_prob))\n",
    "print(\"Recall:\", recall_score(y_test, log_pred))\n",
    "print(\"Precision:\", precision_score(y_test, log_pred))\n",
    "print(\"F1:\", f1_score(y_test, log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fecbe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "ROC-AUC: 0.6471283249018593\n",
      "Recall: 0.4565123323236694\n",
      "Precision: 0.21057884231536927\n",
      "F1: 0.2882119928971452\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "rf_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test, rf_prob))\n",
    "print(\"Recall:\", recall_score(y_test, rf_pred))\n",
    "print(\"Precision:\", precision_score(y_test, rf_pred))\n",
    "print(\"F1:\", f1_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a1ce73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest (Threshold 0.35) ===\n",
      "Recall: 0.694937256598875\n",
      "Precision: 0.14786852039407053\n",
      "F1: 0.24385059216519892\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "threshold = 0.35\n",
    "rf_custom_pred = (rf_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"=== Random Forest (Threshold 0.35) ===\")\n",
    "print(\"Recall:\", recall_score(y_test, rf_custom_pred))\n",
    "print(\"Precision:\", precision_score(y_test, rf_custom_pred))\n",
    "print(\"F1:\", f1_score(y_test, rf_custom_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608ebd6",
   "metadata": {},
   "source": [
    "Model Evaluation Summary\n",
    "\n",
    "The Logistic Regression baseline showed limited performance (ROC-AUC ≈ 0.58) and very low recall (~6%), making it unsuitable for business deployment.\n",
    "The Random Forest model significantly improved performance:\n",
    "ROC-AUC ≈ 0.65\n",
    "Recall ≈ 46%\n",
    "Precision ≈ 21%\n",
    "F1 ≈ 0.29\n",
    "\n",
    "Lowering the classification threshold to 0.35 increased recall to ~69% but reduced precision substantially (~15%), leading to a lower overall F1 score.\n",
    "Given the trade-off between recall and operational noise, the default threshold (0.5) provides a more balanced and practical deployment setting.\n",
    "The Random Forest model was selected as the final model due to its improved discrimination and better recall of low-rating orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59692066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
